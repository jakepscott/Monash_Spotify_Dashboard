---
title: "Untitled"
author: "Jake Scott"
date: "6/13/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---
## Load Data
```{r Load Libs and Data}
library(tidyverse)
library(tidymodels)
library(here)
doParallel::registerDoParallel()
pop_songs_data <- read_rds(here("data/Full_Popular_Songs.rds"))
pop_songs_data <- pop_songs_data %>% 
  distinct(track_id,.keep_all = T) %>% 
  na.omit()
```


### Clean data
```{r}
set.seed(13)

#Taking all but the hold out data
full_data <- pop_songs_data %>% 
  #Remove identified columns
  select(-contains("id"), -contains('name')) %>%
  #Make logical outcome into character
  mutate(liked=case_when(liked==T~"Liked",
                         liked==F~"Not Liked")) %>% 
  #make character columns factors
  mutate(across(where(is.character), as.factor)) %>% 
  mutate(liked=as.factor(liked)) %>% 
  select(-type) %>% 
  mutate(track_release_date=as.numeric(track_release_date)) %>% 
  mutate(key=as.factor(key),
         mode=as.factor(mode),
         time_signature=as.factor(time_signature)) %>% 
  mutate(across(where(is.numeric),as.numeric))

```


### Set test and train data

```{r}
library(tidymodels)
set.seed(13)

#Splitting the data
data_split <- initial_split(full_data, strata = liked)
data_train <- training(data_split)
data_test <- testing(data_split)

#Create cross validation folds
set.seed(123)
data_folds <- vfold_cv(data_train) #Each of these is a cross validation fold. With a training and hold out for each fold.
#We use the second value in a given split to evaluate our model. We use it to compare and tune data. We save the test data for the very end. The resample things we use every time thru our modeling process to make choices
```



### Set up glm model
```{r}
library(ranger)
glm_spec <- logistic_reg() %>% 
  set_engine("glm")
```


### Set metrics
```{r}
mset <- metric_set(sensitivity, specificity)
m_sensitivty <- metric_set(sensitivity)
```


### Set up recipe, workflow
```{r Feature Engineering}
library(textrecipes) #For tokenizing genres
library(themis) # for upsampling
#This is data preprocessing
data_recipe <- recipe(liked ~ ., data = data_train) %>% 
  #Let's add steps. These are steps we take for feature engineering
  #These three steps takes the comma separated genre column and create a column for 
  # each one of the genres, with a 0-1 for whether that song is that genre
  step_tokenize(genres, token = "regex", options = list(pattern = ",")) %>% 
  step_tokenfilter(genres, max_tokens = 125) %>% 
  step_tf(genres) %>% 
  #Take the log to stop the skew of certain features
  step_log(duration_ms, speechiness, acousticness, instrumentalness, 
           liveness, artist_popularity, artist_followers, 
           base = 10, offset = 1) %>% 
  #This will turn the factor vars into dummys
  step_dummy(all_nominal(), -liked) %>% 
  #This will make new examples of songs I like using nearest neighbors of the already-existing songs I do like.
  # It will make it so we have the same number of songs for liked and not liked, adding to the liked using nearest neighbors
  step_smote(liked)

#Set workflow
data_wf <- workflow() %>% 
  add_recipe(data_recipe) %>% 
  add_model(glm_spec)

#tuning reveals that 125 is the optimum value for max_tokens, bringing sensitivity from 0.67 to 0.683
# cv <- data_wf %>% 
#   tune_grid(data_folds, 
#             grid = crossing(max_tokens = seq(150,150,10)),
#             metrics = m_sensitivty)
# 
# cv %>% 
#   autoplot()


#Run the model without tuning
cv <- data_wf %>%
  fit_resamples(data_folds,
                metrics = mset,
                control = control_resamples(save_pred=T))
cv %>%
  collect_metrics()
```


### Evaluate
```{r}
data_final <- data_wf %>% 
  last_fit(data_split)
```

### Save model

```{r}
#Save workflow
saveRDS(data_wf, here("Spotify_Application/model_publish/logistic_workflow.rds"))
#Save logistic regression
saveRDS(data_final, here("Spotify_Application/model_publish/logistic_model.rds"))
```

### View Coefficients
```{r}
data_final %>% 
  pull(.workflow) %>% 
  pluck(1) %>% 
  broom::tidy(exponentiate=T) %>% #Give us odds ratio 
  arrange(desc(abs(estimate))) %>% 
  filter(!str_detect(term,"genre"))

```

### Collect metrics
```{r}
data_final <- read_rds(here("model/logistic_model.rds"))

accuracy <- data_final %>% 
  collect_metrics() %>% 
  filter(.metric=="accuracy") %>% 
  pull(.estimate)

confusion_matix <- collect_predictions(data_final) %>% 
  conf_mat(liked,.pred_class) 

data_final %>% 
  pull(.workflow) %>% 
  pluck(1) %>% 
  tidy() %>% 
  filter(!str_detect(term,"genre"), 
         term!="(Intercept)") %>% 
  mutate(term=str_replace_all(term,"_"," "),
         term=str_to_title(term)) %>% 
  ggplot(aes(estimate, fct_reorder(term,estimate))) +
  geom_vline(xintercept = 0, color="grey70", linetype="dashed", size=1) +
  geom_errorbar(aes(xmin=estimate-std.error,
                    xmax=estimate+std.error),
                width=0.2, alpha=0.7) +
  geom_point() +
  labs(y=NULL,
       x="Coefficient",
       title="I am more likely to like a speechy and energetic song, \nless likely to like a long song from a popular artist",
       subtitle = "Estimates from logistic classification model, thus one should focus \non direction and magnitude") +
  theme_minimal() +
  theme(plot.title.position = "plot")sensitivity <- 50/73
specificity <- 1360/(396+1360)

metrics <- tibble(accuracy=accuracy, sensitivity=sensitivity, specificity=specificity)
saveRDS(metrics,here("model/model_metrics.rds"))

```


### Plots

#### Non genre terms
```{r}
data_final <- readRDS(here("model/logistic_model.rds"))




```

#### Genre terms
```{r}
top <- data_final %>% 
  pull(.workflow) %>% 
  pluck(1) %>% 
  tidy() %>% 
  filter(str_detect(term,"genre"), 
         term!="(Intercept)") %>% 
  filter(p.value<0.1) %>% 
  arrange(desc(estimate)) %>% 
  slice_head(n = 10)


bottom <- data_final %>% 
  pull(.workflow) %>% 
  pluck(1) %>% 
  tidy() %>% 
  filter(str_detect(term,"genre"), 
         term!="(Intercept)") %>% 
  filter(p.value<0.1) %>% 
  arrange(desc(estimate)) %>% 
  slice_tail(n = 10)

top %>% 
  bind_rows(bottom) %>% 
  mutate(term=str_remove(term,"tf_genres_"),
         term=str_remove_all(term,"`"),
         term=str_to_title(term)) %>% 
  ggplot(aes(estimate, fct_reorder(term,estimate))) +
  geom_vline(xintercept = 0, color="grey70", linetype="dashed", size=1) +
  geom_errorbar(aes(xmin=estimate-std.error,
                    xmax=estimate+std.error),
                width=0.2, alpha=0.7) +
  geom_point() +
  labs(y=NULL,
       x="Coefficient",
       title="I am more likely to like a song by a UK Pop or Detroit \nHip Hop artist, but not from a Metropopolis or Emo artist",
       subtitle = "Estimates from logistic classification model, thus one should focus \non direction and magnitude") +
  theme_minimal() +
  theme(plot.title.position = "plot")
```