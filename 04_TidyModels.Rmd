---
title: "Tidymodels"
author: "Jake Scott"
date: "6/13/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---
## Load Data
```{r Load Libs and Data}
library(tidyverse)
library(tidymodels)
library(here)
pop_songs_data <- read_rds(here("data/Full_Popular_Songs.rds"))
pop_songs_data <- pop_songs_data %>% 
  distinct(track_id,.keep_all = T) %>% 
  na.omit()
```

## Explore Data
```{r Skim and Look for Logs}
library(skimr)
pop_songs_data %>% 
  skim()
#I should log duration, speechiness, acousticness,  instrumentalness, liveness, artist popularity and artist followers            
pop_songs_data %>% 
  ggplot(aes(log10(artist_followers))) +
  geom_density()
```

```{r Checking Missings}
#Note that the proportion of "liked" in the missing rows is essentially identical to the 
# proportion of liked in non-missing rows, so I feel okay dropping them. I should see if there are other chars
# unique to the ones with missing values
pop_songs_data %>% 
  select(track_name, track_id, artist_name, album_name, liked) %>% 
  filter(!is.na(artist_name) & !is.na(album_name)) %>% 
  count(liked)

pop_songs_data %>% 
  select(track_name, track_id, artist_name, album_name, liked) %>% 
  filter(is.na(artist_name) | is.na(album_name)) %>% 
  count(liked)
```

## Set up to model
```{r}
set.seed(13)
#This is a true hold out I will not touch even once until a final prediction moment
holdout <- pop_songs_data %>% 
  slice_sample(prop=0.01)

#Taking all but the hold out data
full_data <- pop_songs_data %>% 
  filter(track_id %ni% holdout$track_id)

#Getting rid of ID cols, make liked into a factor
full_data <- full_data %>% 
  #Remove identified columns
  select(-contains("id"), -contains('name')) %>%
  #Make logical outcome into character
  mutate(liked=case_when(liked==T~"Liked",
                         liked==F~"Not Liked")) %>% 
  #make character columns factors
  mutate(across(where(is.character), as.factor)) %>% 
  mutate(liked=as.factor(liked)) %>% 
  select(-type) %>% 
  mutate(track_release_date=as.numeric(track_release_date))

```


## Model
### Set up data
```{r}
library(tidymodels)
set.seed(13)

#Splitting the data
data_split <- initial_split(full_data, strata = liked)
data_train <- training(data_split)
data_test <- testing(data_split)

#Create cross validation folds
set.seed(123)
data_folds <- vfold_cv(data_train) #Each of these is a cross validation fold. With a training and hold out for each fold.
#We use the second value in a given split to evaluate our model. We use it to compare and tune data. We save the test data for the very end. The resample things we use every time thru our modeling process to make choices
```


### Feature engineering
```{r Feature Engineering}
library(textrecipes) #For tokenizing genres
library(themis) # for upsampling
#This is data preprocessing
data_recipe <- recipe(liked ~ ., data = data_train) %>% 
  #Let's add steps. These are steps we take for feature engineering
  #These three steps takes the comma separated genre column and create a column for 
  # each one of the genres, with a 0-1 for whether that song is that genre
  step_tokenize(genres, token = "regex", options = list(pattern = ",")) %>% 
  step_tokenfilter(genres, max_tokens = 10) %>% 
  step_tf(genres) %>% 
  #Take the log to stop the skew of certain features
  step_log(duration_ms, speechiness, acousticness, instrumentalness, 
           liveness, artist_popularity, artist_followers, 
           base = 10, offset = 1) %>% 
  #This will make new examples of songs I like using nearest neighbors of the already-existing songs I do like.
  # It will make it so we have the same number of songs for liked and not liked, adding to the liked using nearest neighbors
  step_smote(liked)
  
#Set workflow
data_wf <- workflow() %>% 
  add_recipe(data_recipe)

```


```{r View Recipe}
data_recipe %>% 
  prep() %>% 
  juice() %>% 
  View()
```


### Set models
```{r}
library(ranger)
glm_spec <- logistic_reg() %>% 
  set_engine("glm")

rf_spec <- rand_forest(trees=1000) %>% 
  set_engine("ranger") %>% 
  set_mode("classification")
```

### Add model to workflow

#### Logistic
```{r}
doParallel::registerDoParallel()

glm_rs <- data_wf %>% 
  add_model(glm_spec) %>% 
  fit_resamples(
    resamples = data_folds,
    metrics = metric_set(roc_auc,accuracy, sensitivity, specificity),
    control = control_resamples(save_pred=T)
  )

glm_rs

```


#### Random Forest
```{r}

rf_rs <- data_wf %>% 
  add_model(rf_spec) %>% 
  fit_resamples(
    resamples = data_folds,
    metrics = metric_set(roc_auc,accuracy, sensitivity, specificity),
    control = control_resamples(save_pred=T)
  )

rf_rs

```

### Evaluate models
```{r}
collect_metrics(glm_rs)
collect_metrics(rf_rs)

glm_rs %>% 
  conf_mat_resampled()

rf_rs %>% 
  conf_mat_resampled()
```

Logistic reg did far better, with a sensitivity (which is how well we identify songs I liked.) 
I get around 62% of songs correctly identified as ones that I would like. (I only get 70% or so
of songs I don't like correct though, which is bad, but not what I am looking for so idc.)


```{r}
glm_rs %>% 
  collect_predictions() %>% 
  group_by(id) %>% 
  roc_curve(liked, .pred_Liked) %>% 
  autoplot()

```



